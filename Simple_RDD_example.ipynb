{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWZY6rHUle8uPtiPetNv4H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kuvuklija/Spark-Stepic/blob/main/Simple_RDD_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Устанавливаем PySpark"
      ],
      "metadata": {
        "id": "CU3MiJ2LdK0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RaD4ginvCeNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "conf = SparkConf().setAppName(\"Simple RDD Example\").setMaster(\"local[*]\")\n",
        "sc = SparkContext(conf=conf)\n",
        "\n",
        "numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "rdd = sc.parallelize(numbers)\n",
        "\n",
        "even_numbers_rdd = rdd.filter(lambda x: x % 2 == 0)\n",
        "\n",
        "sum_even_numbers = even_numbers_rdd.sum()\n",
        "\n",
        "print('Четные числа:', even_numbers_rdd.collect())\n",
        "print('Сумма четных чисел:', sum_even_numbers)\n",
        "\n",
        "sc.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqKH2Lvjdq2Z",
        "outputId": "8bde36f6-0ff3-4593-fb7b-68e1b473a996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Четные числа: [2, 4, 6, 8, 10]\n",
            "Сумма четных чисел: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATING DATAFRAME 3 methods\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "spark = SparkSession.builder.appName(\"DataFrame Example\").getOrCreate()\n",
        "data = [(\"Alice\", 1), (\"Bob\", 2), (\"Cathy\", 3)]\n",
        "\n",
        "# create explicit schema\n",
        "schema = StructType([\n",
        "    StructField(\"Name\", StringType(), True),\n",
        "    StructField(\"Value\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "# 1. create DataFrame with explicit schema\n",
        "df = spark.createDataFrame(data, schema)\n",
        "#df.printSchema()\n",
        "\n",
        "# 2. automate set schema by reading data from csv\n",
        "data = [{\"name\": \"Alice\", \"age\": 29},\n",
        "        {\"name\": \"John\", \"age\": 32},\n",
        "        {\"name\": \"Bob\", \"age\": 67},\n",
        "        ]\n",
        "df_auto = spark.createDataFrame(data)\n",
        "#df_auto.printSchema()\n",
        "#df_auto.show()\n",
        "\n",
        "# 3. create from RDD\n",
        "data = [(\"Alice\", 29), (\"Bob\", 98), (\"Cathy\", 32), (\"Molly\", 32)]\n",
        "rdd = spark.sparkContext.parallelize(data)\n",
        "df = rdd.toDF([\"name\", \"age\"])\n",
        "df.show()\n",
        "\n",
        "#print(df.take(2))\n",
        "df.select('name')#.show()\n",
        "df.selectExpr(\"age + 50 as age_plus_50\", \"name\")#.show()\n",
        "df.filter(df[\"age\"]>30)#.show()\n",
        "df.where(df[\"age\"] > 30)#.show()\n",
        "df.groupBy(\"age\").count().show()\n",
        "\n",
        "from pyspark.sql.functions import avg, max\n",
        "df.agg(\n",
        "    avg(\"age\").alias(\"average_age\"),\n",
        "    max(\"age\").alias(\"max_age\")\n",
        ").show()\n",
        "\n",
        "df.orderBy(df[\"age\"].desc()).show()\n",
        "df.sort('age', ascending=False).show()\n",
        "\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rOb-ZtVNM5c",
        "outputId": "ca93f384-0414-470a-af28-bf6e41798863",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "|Alice| 29|\n",
            "|  Bob| 98|\n",
            "|Cathy| 32|\n",
            "|Molly| 32|\n",
            "+-----+---+\n",
            "\n",
            "+---+-----+\n",
            "|age|count|\n",
            "+---+-----+\n",
            "| 29|    1|\n",
            "| 98|    1|\n",
            "| 32|    2|\n",
            "+---+-----+\n",
            "\n",
            "+-----------+-------+\n",
            "|average_age|max_age|\n",
            "+-----------+-------+\n",
            "|      47.75|     98|\n",
            "+-----------+-------+\n",
            "\n",
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "|  Bob| 98|\n",
            "|Cathy| 32|\n",
            "|Molly| 32|\n",
            "|Alice| 29|\n",
            "+-----+---+\n",
            "\n",
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "|  Bob| 98|\n",
            "|Cathy| 32|\n",
            "|Molly| 32|\n",
            "|Alice| 29|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install pyspark avro\n",
        "# sudo apt install python3-avro\n",
        "\n",
        "# Запись данных в Avro\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "        .config(\"spark.jars.packages\", \"org.apache.spark:spark-avro_2.12:3.5.1\")\n",
        "        .appName(\"Read\")\n",
        "        .getOrCreate()\n",
        ")\n",
        "data = [(\"Alice\", 25), (\"Bob\", 30), (\"Vadim\", 46)]\n",
        "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
        "df.write.format(\"avro\").save(\"./Avro_Files/1\")"
      ],
      "metadata": {
        "id": "Q62WVo328wIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# чтение данных с помощью RDD\n",
        "from pyspark import SparkContext\n",
        "\n",
        "sc = SparkContext(\"local\", \"Read text file example\")\n",
        "rdd = sc.textFile(\"/content/sample_data/text.txt\")\n",
        "\n",
        "# обработка данных\n",
        "words = rdd.flatMap(lambda line: line.split(\" \"))\n",
        "word_count = words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# вывод результата\n",
        "print(word_count.collect())\n",
        "\n",
        "sc.stop()"
      ],
      "metadata": {
        "id": "P1wJ1L6liMNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cadd202c-6fc6-4819-a003-c00b90cca830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('John', 3), ('Snow', 1), ('my', 1), ('favorit', 1), ('hero', 1), ('Hello', 1), ('World', 2), ('broooo', 1), ('yoooo', 1), ('I', 1), ('love', 1), ('you', 1), ('persik', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# РАБОТА С RDD\n",
        "\n",
        "from pyspark import SparkContext,  SparkConf\n",
        "\n",
        "conf = SparkConf().setAppName(\"File\").setMaster(\"local[*]\")\n",
        "sc = SparkContext(conf=conf)\n",
        "\n",
        "rdd = sc.textFile(\"./sample_data/README.txt\")\n",
        "lines = rdd.filter(lambda line: \"mnist\" in line)\n",
        "print(lines.collect())\n",
        "\n",
        "rdd = sc.textFile(\"/content/test.csv\")\n",
        "lines = rdd.map(lambda line: line.split(\",\"))\n",
        "print(lines.take(3))\n",
        "\n",
        "# ищем в 1 колонке по имени Ariela ---> искомая строка\n",
        "filtered_rdd = lines.filter(lambda cols: cols[1]=='Ariela')\n",
        "\n",
        "# сохраняем файл --> получим несколько файлов в новой папке content (отказоустойчивость)\n",
        "filtered_rdd.saveAsTextFile(\"content\")\n",
        "\n",
        "print(filtered_rdd.collect())\n",
        "\n",
        "sc.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhJXGZIj7dM",
        "outputId": "77f089cd-0d64-4279-fd29-f77564310f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['*   `mnist_*.csv` is a small sample of the', '    described at: http://yann.lecun.com/exdb/mnist/']\n",
            "[['id', 'firstname', 'lastname', 'email', 'email2', 'profession'], ['100', 'Tera', 'Rozanna', 'Tera.Rozanna@yopmail.com', 'Tera.Rozanna@gmail.com', 'worker'], ['101', 'Cathyleen', 'Swigart', 'Cathyleen.Swigart@yopmail.com', 'Cathyleen.Swigart@gmail.com', 'worker']]\n",
            "[['106', 'Ariela', 'Chrystel', 'Ariela.Chrystel@yopmail.com', 'Ariela.Chrystel@gmail.com', 'police officer']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# РАБОТА С DATAFRAME\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "  .appName('read') \\\n",
        "  .getOrCreate()\n",
        "\n",
        "# чтение\n",
        "df = spark.read.csv(\"/content/test.csv\", header=True)\n",
        "df.show()\n",
        "\n",
        "# запись в csv (в несколько партиций, чтобы хранить данные в HDFS)\n",
        "df.write.mode(\"overwrite\").option(\"header\", 'true').csv(\"result_csv\")\n",
        "\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDdTL3sUDjCs",
        "outputId": "a1cf329a-e1ae-4c85-b6c3-75c1b14ef5da",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+----------+--------------------+--------------------+--------------+\n",
            "| id|firstname|  lastname|               email|              email2|    profession|\n",
            "+---+---------+----------+--------------------+--------------------+--------------+\n",
            "|100|     Tera|   Rozanna|Tera.Rozanna@yopm...|Tera.Rozanna@gmai...|        worker|\n",
            "|101|Cathyleen|   Swigart|Cathyleen.Swigart...|Cathyleen.Swigart...|        worker|\n",
            "|102|  Sherrie|      Cath|Sherrie.Cath@yopm...|Sherrie.Cath@gmai...|        doctor|\n",
            "|103|    Marti|      Bluh|Marti.Bluh@yopmai...|Marti.Bluh@gmail.com|        worker|\n",
            "|104|    Diena|Hieronymus|Diena.Hieronymus@...|Diena.Hieronymus@...|     developer|\n",
            "|105|    Fayre|   Armanda|Fayre.Armanda@yop...|Fayre.Armanda@gma...|police officer|\n",
            "|106|   Ariela|  Chrystel|Ariela.Chrystel@y...|Ariela.Chrystel@g...|police officer|\n",
            "|107|   Valeda|    Philoo|Valeda.Philoo@yop...|Valeda.Philoo@gma...|police officer|\n",
            "|108|    Codie|     Melan|Codie.Melan@yopma...|Codie.Melan@gmail...|        doctor|\n",
            "|109|     Dede|    Wittie|Dede.Wittie@yopma...|Dede.Wittie@gmail...|        worker|\n",
            "|110|Rosabelle|     Argus|Rosabelle.Argus@y...|Rosabelle.Argus@g...|        doctor|\n",
            "|111|  Ottilie|    Nedrud|Ottilie.Nedrud@yo...|Ottilie.Nedrud@gm...|   firefighter|\n",
            "|112|Esmeralda|    Dituri|Esmeralda.Dituri@...|Esmeralda.Dituri@...|     developer|\n",
            "|113|    Paule|   Valerio|Paule.Valerio@yop...|Paule.Valerio@gma...|police officer|\n",
            "|114|  Krystle|   Voletta|Krystle.Voletta@y...|Krystle.Voletta@g...|police officer|\n",
            "|115|    Addia|   Weinreb|Addia.Weinreb@yop...|Addia.Weinreb@gma...|police officer|\n",
            "|116|Cristabel|    Jethro|Cristabel.Jethro@...|Cristabel.Jethro@...|        worker|\n",
            "|117|   Feliza|    Dominy|Feliza.Dominy@yop...|Feliza.Dominy@gma...|police officer|\n",
            "|118| Brandise|  Hepsibah|Brandise.Hepsibah...|Brandise.Hepsibah...|        doctor|\n",
            "|119|   Drucie|     Ricki|Drucie.Ricki@yopm...|Drucie.Ricki@gmai...|     developer|\n",
            "+---+---------+----------+--------------------+--------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Использование sql-подобных функций\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"DataFrame API Example\").getOrCreate()\n",
        "\n",
        "df = spark.read.json(\"/content/people.json\")\n",
        "\n",
        "# фильтрация\n",
        "filtered_df = df.filter(col(\"age\") > 30)\n",
        "\n",
        "# группировка\n",
        "grouped_df = df.groupBy(\"department\").agg({\"age\":\"avg\", \"name\":\"count\"}) \\\n",
        "  .withColumnRenamed(\"count(name)\", \"count\") \\\n",
        "  .withColumnRenamed(\"avg(age)\", \"avg_age\")\n",
        "\n",
        "# сортировка\n",
        "sorted_df = grouped_df.filter(col(\"avg_age\").isNotNull()).orderBy(col(\"count\").desc())\n",
        "\n",
        "filtered_df.show()\n",
        "sorted_df.show()\n",
        "\n",
        "sorted_df.write.csv('output.csv', header=True)\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yLCcGpzx7rS0",
        "outputId": "7487081a-a818-43e7-d278-f95cc6c19c20"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+---+----------+----+\n",
            "|_corrupt_record|age|department|name|\n",
            "+---------------+---+----------+----+\n",
            "|           NULL| 35|        HR|Jane|\n",
            "|           NULL| 40|   Finance|Mark|\n",
            "+---------------+---+----------+----+\n",
            "\n",
            "+-----------+-----+-------+\n",
            "| department|count|avg_age|\n",
            "+-----------+-----+-------+\n",
            "|         HR|    2|   32.5|\n",
            "|    Finance|    2|   32.5|\n",
            "|Engineering|    1|   23.0|\n",
            "+-----------+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Использование SQL (DataFrame --> временные вьюхи)\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SQLAPIExample\").getOrCreate()\n",
        "\n",
        "people_df = spark.read.json(\"/content/people.json\")\n",
        "department_df = spark.read.json(\"/content/department.json\")\n",
        "\n",
        "# DF как временные представления SQL\n",
        "people_df.createOrReplaceTempView(\"people\")\n",
        "department_df.createOrReplaceTempView(\"departments\")\n",
        "\n",
        "join_df = spark.sql(\"\"\"\n",
        "select p.name, p.age, d.department_name\n",
        "from people as p\n",
        "inner join departments as d on d.department_name = p.department\n",
        "\"\"\")\n",
        "\n",
        "join_df.show()\n",
        "\n",
        "join_df.write.csv(\"output_join.csv\", header=True)\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "399c_5wGDsEZ",
        "outputId": "63784fbb-6461-43f6-8693-c1ce4408efc6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+---------------+\n",
            "| name|age|department_name|\n",
            "+-----+---+---------------+\n",
            "| John| 30|             HR|\n",
            "|  Doe| 25|        Finance|\n",
            "| Jane| 35|             HR|\n",
            "| Mark| 40|        Finance|\n",
            "|Smith| 23|    Engineering|\n",
            "+-----+---+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разные JOIN\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Join Examples\").getOrCreate()\n",
        "\n",
        "people_data = [\n",
        "    (\"John\", 30, 1),\n",
        "    (\"Doe\", 25, 2),\n",
        "    (\"Jane\", 35, 1),\n",
        "    (\"Mark\", 40, 2),\n",
        "    (\"Smith\", 23, 3)\n",
        "]\n",
        "people_columns = [\"name\", \"age\", \"department_id\"]\n",
        "people_df = spark.createDataFrame(data= people_data, schema=people_columns)\n",
        "\n",
        "department_data = [\n",
        "    (1, \"HR\"),\n",
        "    (2, \"Finance\"),\n",
        "    (3, \"Engineering\"),\n",
        "    (4, \"Marketing\")\n",
        "]\n",
        "department_columns = ['id', 'department_name']\n",
        "department_df = spark.createDataFrame(data=department_data, schema=department_columns)\n",
        "\n",
        "people_df.show()\n",
        "department_df.show()\n",
        "\n",
        "# INNER JOIN\n",
        "inner_join_df = people_df.join(department_df, people_df.department_id == department_df.id, \"inner\")\n",
        "inner_join_df.show()\n",
        "\n",
        "# LEFT OUTER JOIN\n",
        "left_join_df = department_df.join(people_df, department_df.id == people_df.department_id, \"left_outer\" )\n",
        "left_join_df.show()\n",
        "\n",
        "# RIGHT OUTER JOIN\n",
        "right_join_df = department_df.join(people_df, department_df.id == people_df.department_id, \"right_outer\" )\n",
        "right_join_df.show()\n",
        "\n",
        "# FULL OUTER JOIN\n",
        "full_join_df = department_df.join(people_df, department_df.id == people_df.department_id, \"outer\" )\n",
        "full_join_df.show()\n",
        "\n",
        "# CROSS JOIN\n",
        "cross_join_df = department_df.crossJoin(people_df)\n",
        "cross_join_df.show()\n",
        "\n",
        "# JOIN WITH CONDITION\n",
        "condition_join_df = department_df.join(people_df, (department_df.id == people_df.department_id) & (people_df.age > 30), \"inner\" )\n",
        "condition_join_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfYXSBQFJLU6",
        "outputId": "6ce83460-812a-45d5-adb0-5fc54a4ba4d8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+-------------+\n",
            "| name|age|department_id|\n",
            "+-----+---+-------------+\n",
            "| John| 30|            1|\n",
            "|  Doe| 25|            2|\n",
            "| Jane| 35|            1|\n",
            "| Mark| 40|            2|\n",
            "|Smith| 23|            3|\n",
            "+-----+---+-------------+\n",
            "\n",
            "+---+---------------+\n",
            "| id|department_name|\n",
            "+---+---------------+\n",
            "|  1|             HR|\n",
            "|  2|        Finance|\n",
            "|  3|    Engineering|\n",
            "|  4|      Marketing|\n",
            "+---+---------------+\n",
            "\n",
            "+-----+---+-------------+---+---------------+\n",
            "| name|age|department_id| id|department_name|\n",
            "+-----+---+-------------+---+---------------+\n",
            "| John| 30|            1|  1|             HR|\n",
            "| Jane| 35|            1|  1|             HR|\n",
            "|  Doe| 25|            2|  2|        Finance|\n",
            "| Mark| 40|            2|  2|        Finance|\n",
            "|Smith| 23|            3|  3|    Engineering|\n",
            "+-----+---+-------------+---+---------------+\n",
            "\n",
            "+---+---------------+-----+----+-------------+\n",
            "| id|department_name| name| age|department_id|\n",
            "+---+---------------+-----+----+-------------+\n",
            "|  1|             HR| Jane|  35|            1|\n",
            "|  1|             HR| John|  30|            1|\n",
            "|  2|        Finance| Mark|  40|            2|\n",
            "|  2|        Finance|  Doe|  25|            2|\n",
            "|  3|    Engineering|Smith|  23|            3|\n",
            "|  4|      Marketing| NULL|NULL|         NULL|\n",
            "+---+---------------+-----+----+-------------+\n",
            "\n",
            "+---+---------------+-----+---+-------------+\n",
            "| id|department_name| name|age|department_id|\n",
            "+---+---------------+-----+---+-------------+\n",
            "|  1|             HR| John| 30|            1|\n",
            "|  2|        Finance|  Doe| 25|            2|\n",
            "|  1|             HR| Jane| 35|            1|\n",
            "|  3|    Engineering|Smith| 23|            3|\n",
            "|  2|        Finance| Mark| 40|            2|\n",
            "+---+---------------+-----+---+-------------+\n",
            "\n",
            "+---+---------------+-----+----+-------------+\n",
            "| id|department_name| name| age|department_id|\n",
            "+---+---------------+-----+----+-------------+\n",
            "|  1|             HR| John|  30|            1|\n",
            "|  1|             HR| Jane|  35|            1|\n",
            "|  2|        Finance|  Doe|  25|            2|\n",
            "|  2|        Finance| Mark|  40|            2|\n",
            "|  3|    Engineering|Smith|  23|            3|\n",
            "|  4|      Marketing| NULL|NULL|         NULL|\n",
            "+---+---------------+-----+----+-------------+\n",
            "\n",
            "+---+---------------+-----+---+-------------+\n",
            "| id|department_name| name|age|department_id|\n",
            "+---+---------------+-----+---+-------------+\n",
            "|  1|             HR| John| 30|            1|\n",
            "|  1|             HR|  Doe| 25|            2|\n",
            "|  2|        Finance| John| 30|            1|\n",
            "|  2|        Finance|  Doe| 25|            2|\n",
            "|  1|             HR| Jane| 35|            1|\n",
            "|  1|             HR| Mark| 40|            2|\n",
            "|  1|             HR|Smith| 23|            3|\n",
            "|  2|        Finance| Jane| 35|            1|\n",
            "|  2|        Finance| Mark| 40|            2|\n",
            "|  2|        Finance|Smith| 23|            3|\n",
            "|  3|    Engineering| John| 30|            1|\n",
            "|  3|    Engineering|  Doe| 25|            2|\n",
            "|  4|      Marketing| John| 30|            1|\n",
            "|  4|      Marketing|  Doe| 25|            2|\n",
            "|  3|    Engineering| Jane| 35|            1|\n",
            "|  3|    Engineering| Mark| 40|            2|\n",
            "|  3|    Engineering|Smith| 23|            3|\n",
            "|  4|      Marketing| Jane| 35|            1|\n",
            "|  4|      Marketing| Mark| 40|            2|\n",
            "|  4|      Marketing|Smith| 23|            3|\n",
            "+---+---------------+-----+---+-------------+\n",
            "\n",
            "+---+---------------+----+---+-------------+\n",
            "| id|department_name|name|age|department_id|\n",
            "+---+---------------+----+---+-------------+\n",
            "|  1|             HR|Jane| 35|            1|\n",
            "|  2|        Finance|Mark| 40|            2|\n",
            "+---+---------------+----+---+-------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}